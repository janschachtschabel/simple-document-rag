# ğŸ“š RAG Wissensdatenbank

Ein leistungsstarkes Retrieval-Augmented Generation (RAG) System mit intelligenter Dokumentenverarbeitung, semantischer Suche und Confluence-Integration.

---

## ğŸŒŸ Features

- **Multi-Format Dokumentenverarbeitung**: PDF, Word, Excel, PowerPoint, E-Mails, Bilder, HTML, Markdown und mehr
- **Hybrid-Suche**: Kombiniert semantische Vektorsuche mit BM25 Keyword-Suche (RRF)
- **Cross-Encoder Reranking**: Schnelles, deutschsprachiges Reranking fÃ¼r bessere Relevanz
- **LangGraph Workflow**: Intelligente Query-Analyse und -Umschreibung
- **Confluence Integration**: Direkte Suche in Atlassian Confluence
- **Dokument-Generator**: Automatische Dokumentenerstellung aus Inhaltsverzeichnis
- **Moderne Web-OberflÃ¤che**: Streamlit UI mit Chat-Interface
- **REST API**: FastAPI Backend fÃ¼r programmatischen Zugriff

---

## ğŸ“‹ Voraussetzungen

### System-Anforderungen
- **Python**: 3.10 oder hÃ¶her
- **RAM**: Mindestens 8 GB empfohlen
- **Speicher**: ~2 GB fÃ¼r AbhÃ¤ngigkeiten und Modelle

### BenÃ¶tigte API-Keys
- **OpenAI API Key**: FÃ¼r Embeddings und LLM-Generierung
  - Registrierung: https://platform.openai.com/
- **Confluence API Token** (optional): FÃ¼r Confluence-Integration
  - Erstellung: Atlassian Profil â†’ Security â†’ API tokens

---

## ğŸš€ Installation

### 1. Repository klonen
```bash
git clone <repository-url>
cd windsurf-project
```

### 2. Virtuelle Umgebung erstellen (empfohlen)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python -m venv venv
source venv/bin/activate
```

### 3. AbhÃ¤ngigkeiten installieren
```bash
pip install -r requirements.txt
```

### 4. Umgebungsvariablen konfigurieren
```bash
# .env.example kopieren
copy .env.example .env    # Windows
cp .env.example .env      # Linux/Mac

# .env Datei bearbeiten und API-Key eintragen
```

**Minimale `.env` Konfiguration:**
```env
OPENAI_API_KEY=sk-your-openai-api-key-here
```

**VollstÃ¤ndige `.env` Konfiguration:**
```env
# OpenAI
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4.1-mini
EMBEDDING_MODEL=text-embedding-ada-002

# RAG Einstellungen
CHROMA_PERSIST_DIRECTORY=./chroma_db
MAX_TOKENS=30000
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RETRIEVAL=200

# Confluence (optional)
CONFLUENCE_URL=https://your-domain.atlassian.net/wiki
CONFLUENCE_USERNAME=your-email@example.com
CONFLUENCE_API_KEY=your-api-token
CONFLUENCE_SPACE_KEY=MYSPACE
CONFLUENCE_IS_CLOUD=true
```

---

## â–¶ï¸ Anwendung starten

### Schritt 1: API-Server starten
```bash
python main.py
```
Der API-Server startet auf **http://localhost:8000**

Erfolgreiche Ausgabe:
```
INFO:     Uvicorn running on http://0.0.0.0:8000
INFO:     Application startup complete.
```

### Schritt 2: Streamlit-OberflÃ¤che starten
In einem **neuen Terminal**:
```bash
streamlit run app.py
```
Die Web-OberflÃ¤che Ã¶ffnet sich automatisch auf **http://localhost:8501**

### Beide Dienste gleichzeitig (Windows PowerShell)
```powershell
Start-Process python -ArgumentList "main.py"
Start-Sleep -Seconds 5
streamlit run app.py
```

---

## ğŸ–¥ï¸ BenutzeroberflÃ¤che

### Ãœbersicht
Die OberflÃ¤che ist in zwei Bereiche unterteilt:
- **Linke Seitenleiste**: Dokumentenverwaltung und Einstellungen
- **Hauptbereich**: Chat, Suche und Dokument-Generator

---

## ğŸ“ Seitenleiste - Quellen hinzufÃ¼gen

### Tab: ğŸ“ Datei
Dokumente per Drag & Drop oder Dateiauswahl hochladen.

**UnterstÃ¼tzte Formate:**
| Kategorie | Formate |
|-----------|---------|
| Dokumente | PDF, DOCX, DOC, TXT, MD |
| Tabellen | XLSX, XLS, CSV |
| PrÃ¤sentationen | PPTX, PPT |
| Web | HTML, HTM |
| E-Books | EPUB |
| E-Mails | MSG, EML |
| Bilder | JPG, PNG, GIF (OCR) |
| Daten | JSON, XML |
| Archive | ZIP |

### Tab: ğŸ“ Text
Direktes EinfÃ¼gen von Text in die Wissensdatenbank.

### Tab: ğŸ”— URL
Webseiten als Quelle hinzufÃ¼gen. Der Inhalt wird automatisch extrahiert.

### Tab: ğŸ”· Confluence
Atlassian Confluence als Quelle konfigurieren:
1. **Confluence URL**: `https://domain.atlassian.net/wiki`
2. **Benutzername/E-Mail**: Ihre Atlassian E-Mail
3. **API Token**: Token aus Atlassian Security Settings
4. **Space Key**: Optional, filtert auf bestimmten Space

Buttons:
- **ğŸ’¾ Speichern**: Konfiguration speichern
- **ğŸ” Testen**: Verbindung prÃ¼fen

#### ğŸ”‘ Confluence API-Token erstellen

Confluence Cloud nutzt Atlassian API Tokens (kein OAuth nÃ¶tig).

**Voraussetzungen:**
- Confluence Cloud (nicht Server / Data Center)
- Atlassian-Account mit Zugriff auf das Confluence-Space

**Schritte:**

1. Ã–ffnen Sie die Token-Verwaltung:
   
   ğŸ‘‰ https://id.atlassian.com/manage-profile/security/api-tokens

2. Klicken Sie auf **"Create API token"**

3. Vergeben Sie einen Namen (z.B. "RAG Wissensdatenbank")

4. Klicken Sie auf **"Create"**

5. **Kopieren Sie das Token sofort** (wird nur einmal angezeigt!)

6. Tragen Sie das Token in der App unter ğŸ”· Confluence ein

> âš ï¸ **Wichtig**: Das Token hat dieselben Berechtigungen wie Ihr Account. Teilen Sie es nicht!

---

## ğŸ“‘ Seitenleiste - Meine Quellen

Ãœbersicht aller hochgeladenen Dokumente:
- **Anzahl Quellen** und **Chunks** als Metriken
- Pro Quelle: Name, Chunk-Anzahl, LÃ¶schen-Button
- **ğŸ—‘ï¸ Alle Quellen lÃ¶schen**: Gesamte Wissensdatenbank leeren

---

## âš™ï¸ Seitenleiste - Einstellungen

### AntwortlÃ¤nge
Slider mit drei Optionen:
- **kurz**: 2-3 SÃ¤tze, Kernaussagen
- **normal**: Ausgewogene Antwort (Standard)
- **ausfÃ¼hrlich**: Detaillierte ErklÃ¤rungen

### ğŸ”— Confluence durchsuchen
Checkbox erscheint wenn Confluence konfiguriert ist. Aktivieren um Confluence in die Suche einzubeziehen.

### ğŸ§¹ Chat leeren
LÃ¶scht den Chatverlauf und startet eine neue Konversation.

---

## ğŸ’¬ Hauptbereich - Chat

Das HerzstÃ¼ck der Anwendung. Stellen Sie Fragen zu Ihren Dokumenten.

### Funktionsweise
1. Frage eingeben im Chat-Feld
2. System durchsucht alle Quellen (+ optional Confluence)
3. Relevante Dokumente werden reranked
4. LLM generiert Antwort basierend auf Kontext

### Features
- **Konversationsverlauf**: Vorherige Fragen und Antworten bleiben sichtbar
- **Quellenangabe**: Expandierbarer Bereich zeigt verwendete Quellen
- **Workflow-Log**: Details zur Query-Verarbeitung

### Beispiel-Fragen
- "Was sind die wichtigsten Punkte aus dem Jahresbericht?"
- "Vergleiche die Strategien aus Dokument A und B"
- "Fasse alle Informationen zu Thema X zusammen"

---

## ğŸ” Hauptbereich - Suche

Direkte Dokumentensuche ohne LLM-Generierung.

- Suchbegriff eingeben
- Anzahl Ergebnisse wÃ¤hlen (1-20)
- Ergebnisse zeigen relevante Textpassagen mit Quellenangabe

NÃ¼tzlich fÃ¼r:
- Schnelles Finden spezifischer Informationen
- ÃœberprÃ¼fen welche Dokumente ein Thema behandeln
- Debuggen der Retrieval-QualitÃ¤t

---

## ğŸ“ Hauptbereich - Dokument-Generator

Automatische Erstellung von Dokumenten basierend auf Ihrer Wissensdatenbank.

### Verwendung
1. **Dokumenttitel** eingeben
2. **Inhaltsverzeichnis** erstellen (ein Kapitel pro Zeile)
3. **ğŸ“„ Dokument generieren** klicken
4. Warten bis alle Kapitel generiert sind
5. **ğŸ“¥ Als Markdown herunterladen**

### Beispiel-Inhaltsverzeichnis
```
1. Einleitung
2. Problemstellung
3. LÃ¶sungsansatz
4. Implementierung
5. Ergebnisse
6. Fazit
```

---

## ğŸ”Œ API-Dokumentation

Die API ist unter **http://localhost:8000/docs** dokumentiert (Swagger UI).

### Wichtige Endpoints

| Endpoint | Methode | Beschreibung |
|----------|---------|--------------|
| `/health` | GET | Systemstatus prÃ¼fen |
| `/upload` | POST | Dokument hochladen |
| `/add-text` | POST | Text hinzufÃ¼gen |
| `/add-url` | POST | URL hinzufÃ¼gen |
| `/query-langgraph` | POST | Frage stellen (empfohlen) |
| `/search` | GET | Dokumente suchen |
| `/sources` | GET | Alle Quellen auflisten |
| `/sources/{name}` | DELETE | Quelle lÃ¶schen |
| `/confluence/status` | GET | Confluence-Status |
| `/confluence/search` | GET | Confluence durchsuchen |

### Beispiel: Frage stellen
```python
import requests

response = requests.post(
    "http://localhost:8000/query-langgraph",
    json={
        "question": "Was sind die Hauptthemen?",
        "response_length": "normal",
        "include_confluence": False
    }
)

data = response.json()
print(data["answer"])
print(data["sources"])
```

---

## ğŸ—ï¸ Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BENUTZER                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   STREAMLIT (app.py) - Port 8501                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Chat UI   â”‚  â”‚  Upload    â”‚  â”‚  Quellen   â”‚  â”‚ Confluence â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ HTTP (requests)
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASTAPI (main.py) - Port 8000                 â”‚
â”‚  POST /query-langgraph â”‚ POST /upload â”‚ GET /sources â”‚ ...      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       RAG PIPELINE                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ LangGraph  â”‚  â”‚ Retriever  â”‚  â”‚ ChromaDB   â”‚  â”‚ Confluence â”‚ â”‚
â”‚  â”‚ Workflow   â”‚  â”‚ Hybrid+RRF â”‚  â”‚ VectorDB   â”‚  â”‚  Loader    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        OPENAI API                                â”‚
â”‚           gpt-4.1-mini (LLM) + text-embedding-ada-002           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Komponenten

| Komponente | Datei | Funktion |
|------------|-------|----------|
| **Streamlit UI** | `app.py` | Web-OberflÃ¤che, Chat, Session-State |
| **FastAPI Server** | `main.py` | REST-API, Request-Validierung |
| **LangGraph Workflow** | `graph_workflow.py` | RAG-Pipeline Orchestrierung |
| **Retriever** | `retriever.py` | Hybrid-Suche, Cross-Encoder Reranking |
| **Vector Database** | `vector_db.py` | ChromaDB Wrapper fÃ¼r Embeddings |
| **Document Processor** | `document_processor.py` | Dokumente parsen, chunken |
| **Confluence Loader** | `confluence_loader.py` | Confluence-Integration |
| **RAG Pipeline** | `rag_pipeline.py` | High-Level Orchestrierung |

---

## ï¿½ RAG Workflow

Der LangGraph-Workflow verarbeitet Anfragen in 5 Schritten:

```
START â†’ analyze_query â†’ rewrite_query â†’ retrieve â†’ grade_documents â†’ generate_response â†’ END
```

### 1. Query-Analyse (`analyze_query`)
- Erkennt Query-Typ (factual, summary, comparison, analysis, etc.)
- Bestimmt KomplexitÃ¤t (simple/moderate/complex)
- Extrahiert Keywords fÃ¼r die Suche

### 2. Query-Rewriting (`rewrite_query`)
- Generiert 3-5 Query-Varianten fÃ¼r bessere Abdeckung
- **Multi-Aspekt-Erkennung**: Fragen wie "LOM und IMS LD" werden in separate Queries aufgeteilt
- Original-Query bleibt immer erhalten

### 3. Retrieval (`retrieve`)
- **Hybrid-Suche** fÃ¼r jede Query-Variante:
  - Semantische Suche (Embeddings)
  - BM25 Keyword-Suche
  - RRF (Reciprocal Rank Fusion) zum Kombinieren
- Boost (+50%) fÃ¼r Dokumente die von mehreren Queries gefunden werden
- Bis zu 40/80/100 Dokumente je nach KomplexitÃ¤t

### 4. Reranking (`grade_documents`)
- **Cross-Encoder** (mmarco-mMiniLMv2) fÃ¼r prÃ¤zises Relevanz-Scoring
- Score-Bereich: -10 bis +10 (normalisiert auf 0-100%)
- Nur Sortierung, kein Filtering (alle Dokumente bleiben erhalten)

### 5. Antwort-Generierung (`generate_response`)
- **40 Chunks** fÃ¼r normale Anfragen
- **80 Chunks** fÃ¼r Zusammenfassungen/Ãœbersichten
- System-Prompt mit Multi-Aspekt-Anweisung
- gpt-4.1-mini mit max. 30.000 Tokens

---

## ğŸ“¦ Bibliotheken & Tools

### Web-Framework
| Bibliothek | Zweck |
|------------|-------|
| FastAPI | REST-API Backend |
| Uvicorn | ASGI Server |
| Streamlit | Web-UI Frontend |

### LLM & RAG
| Bibliothek | Zweck |
|------------|-------|
| LangChain | LLM-Abstraktion, Document Loaders |
| LangGraph (â‰¥0.2.0) | Workflow-Orchestrierung |
| OpenAI | API-Client (gpt-4.1-mini, ada-002) |

### Vector DB & Search
| Bibliothek | Zweck |
|------------|-------|
| ChromaDB | Vektor-Datenbank |
| Sentence-Transformers | Cross-Encoder Reranking |
| Rank-BM25 | Keyword-Suche |

### Dokument-Verarbeitung
| Bibliothek | Zweck |
|------------|-------|
| Markitdown[all] | Universal-Converter (PDF, DOCX, PPTX, etc.) |
| BeautifulSoup4 | HTML-Parsing |

### Confluence-Integration
| Bibliothek | Zweck |
|------------|-------|
| LangChain-Community | ConfluenceLoader |
| Atlassian-Python-API | Confluence API-Client |

---

## ï¿½ğŸ”§ Fehlerbehebung

### API startet nicht
```bash
# Port bereits belegt?
netstat -ano | findstr :8000

# Prozess beenden (Windows)
taskkill /F /PID <PID>
```

### Streamlit Verbindungsfehler
Stellen Sie sicher, dass die API lÃ¤uft bevor Streamlit gestartet wird.

### OpenAI Fehler
- API-Key korrekt in `.env`?
- Ausreichend Credits auf dem OpenAI Account?

### Confluence Verbindung fehlgeschlagen
- URL korrekt? (mit `/wiki` am Ende fÃ¼r Cloud)
- API Token aktuell?
- Benutzername = E-Mail Adresse

### Langsame Antworten
- Erste Anfrage lÃ¤dt Cross-Encoder Modell (~30s)
- Folgende Anfragen sind deutlich schneller

---

## ğŸ“„ Lizenz

MIT License

---

## ğŸ¤ Beitragen

Pull Requests sind willkommen! Bitte erstellen Sie zuerst ein Issue fÃ¼r grÃ¶ÃŸere Ã„nderungen.
